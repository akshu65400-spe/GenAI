# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KRy3_OO68ukZys21j9mLgsDolW8APRRH
"""

from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain_openai import AzureChatOpenAI
from dotenv import load_dotenv
import os

load_dotenv()

llm = AzureChatOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    deployment_name=os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT"),
    model_name = "gpt-5-mini",
    temperature=0.7
)

chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a polite and knowledgeable AI assistant. Do not answer questions from the medical domain."),
    ("user", "{topic}")
])

pipeline = LLMChain(
    llm=llm,
    prompt=chat_prompt
)

result = pipeline.invoke(topic="Machine Learning")
print(result['text'])

'''
prompts:
simple prompt
chatprompttemplate
few short prompt template
RAG prompt template
'''